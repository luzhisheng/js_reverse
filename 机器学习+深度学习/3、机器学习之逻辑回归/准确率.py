import numpy as np
from æ”¯æŒä¸­æ–‡ import init_plot
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_moons
from sklearn.metrics import accuracy_score


SHOW_PLOT = init_plot()

# ===== ç”Ÿæˆæœˆç‰™å½¢æ•°æ® =====
np.random.seed(42)
X, y = make_moons(n_samples=200, noise=0.15)  # æœˆç‰™å½¢

# ===== äºŒæ¬¡å¤šé¡¹å¼ç‰¹å¾ =====
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X)

# ===== è®­ç»ƒé€»è¾‘å›å½’ =====
clf = LogisticRegression()
clf.fit(X_poly, y)

# ===== è®¡ç®—è®­ç»ƒé›†å‡†ç¡®ç‡ =====
y_pred = clf.predict(X_poly)
acc = accuracy_score(y, y_pred)
print(f"è®­ç»ƒé›†å‡†ç¡®ç‡: {acc:.2%}")

# ===== ç”»å†³ç­–è¾¹ç•Œ =====
xx, yy = np.meshgrid(
    np.linspace(X[:, 0].min() - 0.5, X[:, 0].max() + 0.5, 400),
    np.linspace(X[:, 1].min() - 0.5, X[:, 1].max() + 0.5, 400)
)
grid = np.c_[xx.ravel(), yy.ravel()]
grid_poly = poly.transform(grid)
Z = clf.predict(grid_poly).reshape(xx.shape)

plt.figure(figsize=(6, 6))
plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.3)

# åŸå§‹æ•°æ®
plt.scatter(X[y == 0, 0], X[y == 0, 1], c='blue', label='ç±»åˆ«0', edgecolors='k')
plt.scatter(X[y == 1, 0], X[y == 1, 1], c='red', label='ç±»åˆ«1', edgecolors='k')

plt.xlabel("ç‰¹å¾ 1")
plt.ylabel("ç‰¹å¾ 2")
plt.title(f"é€»è¾‘å›å½’ + äºŒæ¬¡æ›²çº¿ï¼ˆæœˆç‰™å½¢åˆ†ç±»ï¼‰\nå‡†ç¡®ç‡: {acc:.2%}")
plt.legend()
plt.grid(True)
plt.axis('equal')

if SHOW_PLOT:
    plt.show()
else:
    plt.savefig("logistic_moon_degree2.png", dpi=300, bbox_inches='tight')
    print("ğŸ“· å·²ä¿å­˜å›¾ç‰‡ logistic_moon_degree2.png")
